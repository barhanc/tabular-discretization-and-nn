{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01151b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Literal\n",
    "from warnings import simplefilter\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "from mlp import BinnedMLPClassifier, RawMLPClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "\n",
    "simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa2619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    # \"electricity\": 44120,\n",
    "    # \"covertype\": 44121,\n",
    "    # \"pol\": 44122,\n",
    "    # \"house_16H\": 44123,\n",
    "    # \"kdd\": 44124,\n",
    "    # \"MagicTelescope\": 44125,\n",
    "    # \"bank_marketing\": 44126,\n",
    "    # \"phoneme\": 44127,\n",
    "    # \"miniboone\": 44128,\n",
    "    # \"higgs\": 44129,\n",
    "    # \"eye_movements\": 44130,\n",
    "    # \"jannis\": 44131,\n",
    "    # \"credit\": 44089,\n",
    "    # \"california\": 44090,\n",
    "    \"wine\": 44091,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ef59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dataset = wine | size = (2554, 11) | #NaN = 0\n",
      "Fold 0:\n",
      "Baseline TEST ACC. (logregcv) = 75.98%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8b6294df744120b5bc5f5790e2da70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b8840e0e2246978092857b549d3fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def objective(\n",
    "    trial: optuna.Trial,\n",
    "    clf_name: Literal[\"gbdt\", \"bmlp\", \"rmlp\"],\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    X_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    ") -> float:\n",
    "    match clf_name:\n",
    "        case \"gbdt\":\n",
    "            params = {\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-2, 10, log=True),\n",
    "                \"max_depth\": trial.suggest_categorical(\"max_depth\", [None, 2, 3, 4]),\n",
    "                \"min_samples_leaf\": trial.suggest_categorical(\"min_samples_leaf\", [20, 2]),\n",
    "                \"max_leaf_nodes\": trial.suggest_categorical(\"max_leaf_nodes\", [31, 5]),\n",
    "            }\n",
    "            clf = HistGradientBoostingClassifier(**params)\n",
    "\n",
    "        case \"bmlp\":\n",
    "            params = {\n",
    "                \"dim_emb\": trial.suggest_categorical(\"dim_emb\", [4, 8, 16, 24]),\n",
    "                \"dim_hid\": trial.suggest_categorical(\"dim_hid\", [64, 128, 256, 512]),\n",
    "                \"num_hid\": trial.suggest_int(\"num_hid\", 1, 4),\n",
    "                \"num_bins\": trial.suggest_categorical(\"num_bins\", [4, 8, 16, 32, 64, 128]),\n",
    "                \"dropout\": trial.suggest_float(\"dropout\", 0, 0.6),\n",
    "                \"lr\": trial.suggest_float(\"lr\", 3e-4, 3e-3, log=True),\n",
    "                \"batch_size\": trial.suggest_categorical(\"batch_size\", [128, 256, 512]),\n",
    "                \"patience\": trial.suggest_categorical(\"patience\", [50]),\n",
    "                \"max_iter\": trial.suggest_categorical(\"max_iter\", [200]),\n",
    "                \"valid_frac\": trial.suggest_categorical(\"valid_frac\", [0.2]),\n",
    "            }\n",
    "            clf = BinnedMLPClassifier(**params)\n",
    "\n",
    "        case \"rmlp\":\n",
    "            params = {\n",
    "                \"dim_hid\": trial.suggest_categorical(\"dim_hid\", [64, 128, 256, 512]),\n",
    "                \"num_hid\": trial.suggest_int(\"num_hid\", 1, 4),\n",
    "                \"dropout\": trial.suggest_float(\"dropout\", 0, 0.6),\n",
    "                \"lr\": trial.suggest_float(\"lr\", 3e-4, 3e-3, log=True),\n",
    "                \"batch_size\": trial.suggest_categorical(\"batch_size\", [128, 256, 512]),\n",
    "                \"patience\": trial.suggest_categorical(\"patience\", [50]),\n",
    "                \"max_iter\": trial.suggest_categorical(\"max_iter\", [200]),\n",
    "                \"valid_frac\": trial.suggest_categorical(\"valid_frac\", [0.2]),\n",
    "            }\n",
    "            clf = make_pipeline(\n",
    "                QuantileTransformer(output_distribution=\"normal\"),\n",
    "                RawMLPClassifier(**params),\n",
    "            )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    return accuracy_score(y_valid, clf.predict(X_valid))\n",
    "\n",
    "\n",
    "for data_key, data_id in datasets.items():\n",
    "    X: pd.DataFrame\n",
    "    y: pd.DataFrame\n",
    "    X, y = fetch_openml(data_id=data_id, return_X_y=True, as_frame=True)\n",
    "    print(f\"\\ndataset = {data_key} | size = {X.shape} | #NaN = {X.isna().sum().sum()}\")\n",
    "\n",
    "    cat_features = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    num_features = X.select_dtypes(exclude=[\"object\", \"category\"]).columns\n",
    "    assert len(cat_features) == 0\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(StratifiedKFold(n_splits=10, shuffle=True).split(X, y)):\n",
    "        print(f\"Fold {fold_idx}:\")\n",
    "\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "        X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.3, stratify=y_test)\n",
    "\n",
    "        # --- Compute baseline using (CV) logistic regression\n",
    "        clf_lr = make_pipeline(\n",
    "            QuantileTransformer(output_distribution=\"normal\"),\n",
    "            LogisticRegressionCV(random_state=0, max_iter=1_000),\n",
    "        )\n",
    "        clf_lr.fit(X_train, y_train)\n",
    "        acc_lr = accuracy_score(y_test, clf_lr.predict(X_test))\n",
    "        print(f\"Baseline TEST ACC. (logregcv) = {acc_lr:.2%}\")\n",
    "\n",
    "        # --- Tune hyperparams\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "        study_gbdt = optuna.create_study(study_name=\"gbdt\", direction=\"maximize\")\n",
    "        study_bmlp = optuna.create_study(study_name=\"bmlp\", direction=\"maximize\")\n",
    "        study_rmlp = optuna.create_study(study_name=\"rmlp\", direction=\"maximize\")\n",
    "\n",
    "        n_trials = 20\n",
    "        study_gbdt.optimize(\n",
    "            lambda trial: objective(trial, \"gbdt\", X_train, y_train, X_valid, y_valid),\n",
    "            n_trials,\n",
    "            show_progress_bar=True,\n",
    "        )\n",
    "        study_bmlp.optimize(\n",
    "            lambda trial: objective(trial, \"bmlp\", X_train, y_train, X_valid, y_valid),\n",
    "            n_trials,\n",
    "            show_progress_bar=True,\n",
    "        )\n",
    "        study_rmlp.optimize(\n",
    "            lambda trial: objective(trial, \"rmlp\", X_train, y_train, X_valid, y_valid),\n",
    "            n_trials,\n",
    "            show_progress_bar=True,\n",
    "        )\n",
    "\n",
    "        clf_gbdt = HistGradientBoostingClassifier(**study_gbdt.best_params)\n",
    "        clf_bmlp = BinnedMLPClassifier(**study_bmlp.best_params)\n",
    "        clf_rmlp = make_pipeline(\n",
    "            QuantileTransformer(output_distribution=\"normal\"),\n",
    "            RawMLPClassifier(**study_rmlp.best_params),\n",
    "        )\n",
    "\n",
    "        clf_gbdt.fit(X_train, y_train)\n",
    "        clf_bmlp.fit(X_train, y_train)\n",
    "        clf_rmlp.fit(X_train, y_train)\n",
    "\n",
    "        acc_gbdt = accuracy_score(y_test, clf_gbdt.predict(X_test))\n",
    "        acc_bmlp = accuracy_score(y_test, clf_bmlp.predict(X_test))\n",
    "        acc_rmlp = accuracy_score(y_test, clf_rmlp.predict(X_test))\n",
    "\n",
    "        print(f\"GBDT TEST ACC. {acc_gbdt}\")\n",
    "        print(f\"BMLP TEST ACC. {acc_bmlp}\")\n",
    "        print(f\"RMLP TEST ACC. {acc_rmlp}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89b7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"wine\"\n",
    "\n",
    "X: pd.DataFrame\n",
    "y: pd.DataFrame\n",
    "X, y = fetch_openml(\n",
    "    data_id=datasets[key],\n",
    "    return_X_y=True,\n",
    "    as_frame=True,\n",
    ")\n",
    "print(f\"dataset = {key} | size = {X.shape} | #NaN = {X.isna().sum().sum()}\")\n",
    "cat_features = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "num_features = X.select_dtypes(exclude=[\"object\", \"category\"]).columns\n",
    "assert len(cat_features) == 0, \"\"\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(StratifiedKFold(n_splits=5, shuffle=True).split(X, y)):\n",
    "    print(f\"Fold {i}:\")\n",
    "\n",
    "    X_train = X.iloc[train_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    X_test = X.iloc[test_idx]\n",
    "    y_test = y.iloc[test_idx]\n",
    "\n",
    "    clf = make_pipeline(\n",
    "        QuantileTransformer(output_distribution=\"normal\"),\n",
    "        LogisticRegressionCV(max_iter=1_000),\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"LR    {accuracy_score(y_test, clf.predict(X_test)):.2%}\")\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"RF    {accuracy_score(y_test, clf.predict(X_test)):.2%}\")\n",
    "\n",
    "    clf = HistGradientBoostingClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"HGBDT {accuracy_score(y_test, clf.predict(X_test)):.2%}\")\n",
    "\n",
    "    clf = BinnedMLPClassifier(\n",
    "        dim_emb=8,\n",
    "        dim_hid=256,\n",
    "        num_hid=2,\n",
    "        num_bins=8,\n",
    "        dropout=0.1,\n",
    "        lr=1e-3,\n",
    "        max_iter=200,\n",
    "        batch_size=256,\n",
    "        valid_frac=0.2,\n",
    "        patience=50,\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"BMLP {accuracy_score(y_test, clf.predict(X_test)):.2%}\")\n",
    "\n",
    "    clf = make_pipeline(\n",
    "        QuantileTransformer(output_distribution=\"normal\"),\n",
    "        RawMLPClassifier(\n",
    "            dim_hid=256,\n",
    "            num_hid=2,\n",
    "            dropout=0.5,\n",
    "            lr=1e-3,\n",
    "            max_iter=200,\n",
    "            batch_size=256,\n",
    "            valid_frac=0.2,\n",
    "            patience=50,\n",
    "        ),\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"RMLP {accuracy_score(y_test, clf.predict(X_test)):.2%}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1463a06c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
